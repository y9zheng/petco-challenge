{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef88b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "sys.version_info\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c048e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375232, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_data.csv').drop(columns = ['Unnamed: 0'])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5bbf2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data_weekly_loc_dep.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2b9eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = pd.read_csv('store_lookup.txt', sep = '|')\n",
    "store_df = store_df[['LOC_ID', 'DISTRICT', 'MARKET']]\n",
    "\n",
    "df = df.merge(store_df, on = 'LOC_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2668a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['FISCAL_WEEK_ID', 'DEPARTMENT_ID', 'DISTRICT']).agg(\n",
    "            {\n",
    "                \"GROSS_SALES\": \"sum\",\n",
    "                \"PROMO_DISCOUNT\": \"sum\",\n",
    "                \"CLEARANCE_DISCOUNT\": \"sum\",\n",
    "                \"COUPON_DISCOUNT\": \"sum\",\n",
    "                \"MISCELLANOUS_DISCOUNT\": \"sum\",\n",
    "                \"ACTUAL_SALES\": \"sum\",\n",
    "                \"UNITS_SOLD\": \"sum\",\n",
    "                \"INITIAL_MARGIN\": \"sum\",\n",
    "            }\n",
    "        ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a735c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = store_df.groupby(['DISTRICT', 'MARKET'])['LOC_ID'].count().reset_index()\n",
    "# df = df.merge(store_df, on = 'DISTRICT', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2fa01293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(store_df[['DISTRICT', 'MARKET']], on = 'DISTRICT', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a9fd12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add week_num\n",
    "calendar_df = pd.read_csv('fiscal_calendar.txt', sep='|')\n",
    "week_num_df = calendar_df.groupby('FISCAL_WEEK_ID')['DAY_ID'].count().reset_index().reset_index().rename(columns = {'index':'Week_num'})\n",
    "week_num_df = week_num_df[['FISCAL_WEEK_ID', 'Week_num']]\n",
    "df = df.merge(week_num_df, on = 'FISCAL_WEEK_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "448cc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "department_df = pd.read_csv('dept_lookup.txt', sep = '|')\n",
    "df = df.merge(department_df, on = 'DEPARTMENT_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4222002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['department_code'] =  LabelEncoder().fit_transform(df['DEPARTMENT'])\n",
    "df['shop_code'] = LabelEncoder().fit_transform(df['SHOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bdd9c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UNIT_PRICE'] = df['ACTUAL_SALES'] / df['UNITS_SOLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "128bfdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4666812419891357"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine test and df\n",
    "ts = time.time()\n",
    "df = pd.concat([df, test], ignore_index=True, sort=False, keys=['Week_num', 'DEPARTMENT_ID', 'DISTRICT'])\n",
    "df.fillna(0, inplace=True) \n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5dcbd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3ab7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check 0 unit price\n",
    "# df[(df['UNIT_PRICE'] == 0) & (df['UNITS_SOLD'] >0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0cd28ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['Week_num','DEPARTMENT_ID','DISTRICT',col]]\n",
    "    for i in tqdm(lags):\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['Week_num','DEPARTMENT_ID','DISTRICT', col+'_lag_'+str(i)]\n",
    "        shifted['Week_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['Week_num','DEPARTMENT_ID','DISTRICT'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "343f77c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.199804067611694"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "df = lag_feature(df, [4,8,12,26,52], 'ACTUAL_SALES')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5568b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_stats(matrix_, groupby_feats, target, enc_feat, last_periods):\n",
    "    if not 'Week_num' in groupby_feats:\n",
    "        print ('Week_num must in groupby_feats')\n",
    "        return matrix_\n",
    "    \n",
    "    group = matrix_.groupby(groupby_feats)[target].sum().reset_index()\n",
    "    max_lags = np.max(last_periods)\n",
    "    for i in range(1,max_lags+1):\n",
    "        shifted = group[groupby_feats+[target]].copy(deep=True)\n",
    "        shifted['Week_num'] += i\n",
    "        shifted.rename({target:target+'_lag_'+str(i)},axis=1,inplace=True)\n",
    "        group = group.merge(shifted, on=groupby_feats, how='left')\n",
    "    group.fillna(0,inplace=True)\n",
    "    for period in last_periods:\n",
    "        lag_feats = [target+'_lag_'+str(lag) for lag in np.arange(1,period+1)]\n",
    "        # we do not use mean and svd directly because we want to include months with sales = 0\n",
    "        mean = group[lag_feats].sum(axis=1)/float(period)\n",
    "        mean2 = (group[lag_feats]**2).sum(axis=1)/float(period)\n",
    "        group[enc_feat+'_avg_sale_last_'+str(period)] = mean\n",
    "        group[enc_feat+'_std_sale_last_'+str(period)] = (mean2 - mean**2).apply(np.sqrt)\n",
    "        group[enc_feat+'_std_sale_last_'+str(period)].replace(np.inf,0,inplace=True)\n",
    "        # divide by mean, this scales the features for NN\n",
    "        group[enc_feat+'_avg_sale_last_'+str(period)] /= group[enc_feat+'_avg_sale_last_'+str(period)].mean()\n",
    "        group[enc_feat+'_std_sale_last_'+str(period)] /= group[enc_feat+'_std_sale_last_'+str(period)].mean()\n",
    "    cols = groupby_feats + [f_ for f_ in group.columns.values if f_.find('_sale_last_')>=0]\n",
    "    matrix = matrix_.merge(group[cols], on=groupby_feats, how='left')\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "726ce586",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "df = add_group_stats(df, ['Week_num', 'DEPARTMENT_ID'], 'ACTUAL_SALES', 'department', [26,52])\n",
    "df = add_group_stats(df, ['Week_num', 'DISTRICT'], 'ACTUAL_SALES', 'district', [26,52])\n",
    "df = add_group_stats(df, ['Week_num', 'MARKET'], 'ACTUAL_SALES', 'market', [52])\n",
    "df = add_group_stats(df, ['Week_num', 'department_code'], 'ACTUAL_SALES', 'dep', [52])\n",
    "df = add_group_stats(df, ['Week_num', 'shop_code'], 'ACTUAL_SALES', 'shop', [52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebbabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "81af264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first use target encoding each group, then shift month to creat lag features\n",
    "def target_encoding(matrix_, groupby_feats, target, enc_feat, lags):\n",
    "    print ('target encoding for',groupby_feats)\n",
    "    group = matrix_.groupby(groupby_feats).agg({target:'mean'})\n",
    "    group.columns = [enc_feat]\n",
    "    group.reset_index(inplace=True)\n",
    "    matrix = matrix_.merge(group, on=groupby_feats, how='left')\n",
    "    matrix[enc_feat] = matrix[enc_feat].astype(np.float16)\n",
    "    matrix = lag_feature(matrix, lags, enc_feat)\n",
    "    matrix.drop(enc_feat, axis=1, inplace=True)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "338dbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding for ['Week_num']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding for ['Week_num', 'DEPARTMENT_ID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding for ['Week_num', 'DISTRICT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding for ['Week_num', 'MARKET']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding for ['Week_num', 'DEPARTMENT_ID', 'MARKET']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.886138677597046"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "df = target_encoding(df, ['Week_num'], 'ACTUAL_SALES', 'week_avg_actual_sales', [4])\n",
    "df = target_encoding(df, ['Week_num', 'DEPARTMENT_ID'], 'ACTUAL_SALES', 'week_dept_avg_actual_sales', [4,8,12,26,52])\n",
    "df = target_encoding(df, ['Week_num', 'DISTRICT'], 'ACTUAL_SALES', 'week_district_avg_actual_sales', [4,8,12,26,52])\n",
    "df = target_encoding(df, ['Week_num', 'MARKET'], 'ACTUAL_SALES', 'week_market_avg_actual_sales', [4])\n",
    "df = target_encoding(df, ['Week_num', 'DEPARTMENT_ID', 'MARKET'], 'ACTUAL_SALES', 'week_department_market_avg_actual_sales', [4])\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "45d1c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.603397607803345"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = df.groupby(['DEPARTMENT_ID']).agg({'UNIT_PRICE': ['mean']})\n",
    "group.columns = ['department_avg_unit_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "df = pd.merge(df, group, on=['DEPARTMENT_ID'], how='left')\n",
    "df['department_avg_unit_price'] = df['department_avg_unit_price'].astype(np.float16)\n",
    "\n",
    "group = df.groupby(['Week_num','DEPARTMENT_ID']).agg({'UNIT_PRICE': ['mean']})\n",
    "group.columns = ['week_department_avg_unit_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "df = pd.merge(df, group, on=['Week_num','DEPARTMENT_ID'], how='left')\n",
    "df['week_department_avg_unit_price'] = df['week_department_avg_unit_price'].astype(np.float16)\n",
    "\n",
    "lags = [4,8,12,16,20,26]\n",
    "df= lag_feature(df, lags, 'week_department_avg_unit_price')\n",
    "\n",
    "for i in lags:\n",
    "    df['delta_price_lag_'+str(i)] = \\\n",
    "        (df['week_department_avg_unit_price_lag_'+str(i)] - df['department_avg_unit_price']) / df['department_avg_unit_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "df['delta_price_lag'] = df.apply(select_trend, axis=1)\n",
    "df['delta_price_lag'] = df['delta_price_lag'].astype(np.float16)\n",
    "df['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "# https://stackoverflow.com/questions/31828240/first-non-null-value-per-row-from-a-list-of-pandas-columns/31828559\n",
    "# matrix['price_trend'] = matrix[['delta_price_lag_1','delta_price_lag_2','delta_price_lag_3']].bfill(axis=1).iloc[:, 0]\n",
    "# Invalid dtype for backfill_2d [float16]\n",
    "\n",
    "fetures_to_drop = ['department_avg_unit_price', 'week_department_avg_unit_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['week_department_avg_unit_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "df.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7cbeb1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.861367464065552"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "group = df.groupby(['Week_num','DISTRICT']).agg({'ACTUAL_SALES': ['sum']})\n",
    "group.columns = ['week_district_actual_sales']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "df = pd.merge(df, group, on=['Week_num','DISTRICT'], how='left')\n",
    "df['week_district_actual_sales'] = df['week_district_actual_sales'].astype(np.float32)\n",
    "\n",
    "group = group.groupby(['DISTRICT']).agg({'week_district_actual_sales': ['mean']})\n",
    "group.columns = ['district_avg_actual_sales']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "df = pd.merge(df, group, on=['DISTRICT'], how='left')\n",
    "df['district_avg_actual_sales'] = df['district_avg_actual_sales'].astype(np.float32)\n",
    "\n",
    "df['delta_actual_sales'] = (df['week_district_actual_sales'] - df['district_avg_actual_sales']) / df['district_avg_actual_sales']\n",
    "df['delta_actual_sales'] = df['delta_actual_sales'].astype(np.float16)\n",
    "\n",
    "df = lag_feature(df, [4], 'delta_actual_sales')\n",
    "\n",
    "df.drop(['week_district_actual_sales','district_avg_actual_sales','delta_actual_sales'], axis=1, inplace=True)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "45c26ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = pd.read_csv('fiscal_calendar.txt', sep='|')\n",
    "week_num_df = calendar_df.groupby(['FISCAL_WEEK_ID','FISCAL_MONTH_ID'])['DAY_ID'].count().reset_index().reset_index().rename(columns = {'index':'Week_num'})\n",
    "week_num_test = week_num_df.copy()\n",
    "week_num_test['Week_num'] = week_num_test['Week_num'].astype(int) + 52\n",
    "week_num_df = pd.concat([week_num_df, week_num_test.iloc[-52:,]]).reset_index(drop = True)\n",
    "# # week_num_df = week_num_df[['FISCAL_MONTH_ID', 'month_num']]\n",
    "# # df = df.merge(week_num_df, on = 'FISCAL_MONTH_ID', how = 'left')\n",
    "week_num_df[\"Month_num\"] = week_num_df[\"FISCAL_MONTH_ID\"].apply(\n",
    "    lambda x: str(x)[-2:]\n",
    ")\n",
    "df = df.merge(week_num_df[['Week_num', 'Month_num']], on = 'Week_num', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2113d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = (df['Week_num'] / 52).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "88164dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.898027420043945"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Month since last sale for each shop/item pair.\n",
    "ts = time.time()\n",
    "last_sale = pd.DataFrame()\n",
    "for week in range(1,165):    \n",
    "    last_month = df.loc[(df['Week_num']<week)&(df['UNITS_SOLD']>0)].groupby(['DEPARTMENT_ID','DISTRICT'])['Week_num'].max()\n",
    "    new_df = pd.DataFrame({'Week_num':np.ones([last_month.shape[0],])*week,\n",
    "                       'DEPARTMENT_ID': last_month.index.get_level_values(0).values,\n",
    "                       'DISTRICT': last_month.index.get_level_values(1).values,\n",
    "                       'department_district_last_sale': last_month.values})\n",
    "    last_sale = last_sale.append(new_df)\n",
    "last_sale['Week_num'] = last_sale['Week_num'].astype(np.int8)\n",
    "\n",
    "df = df.merge(last_sale, on=['Week_num','DEPARTMENT_ID','DISTRICT'], how='left')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "04970b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.068939447402954"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Month since last sale for each item.\n",
    "ts = time.time()\n",
    "last_sale = pd.DataFrame()\n",
    "for week in range(1,165):    \n",
    "    last_month = df.loc[(df['Week_num']<week)&(df['UNITS_SOLD']>0)].groupby('DEPARTMENT_ID')['Week_num'].max()\n",
    "    new_df = pd.DataFrame({'Week_num':np.ones([last_month.shape[0],])*week,\n",
    "                       'DEPARTMENT_ID': last_month.index.values,\n",
    "                       'department_last_sale': last_month.values})\n",
    "    last_sale = last_sale.append(new_df)\n",
    "last_sale['Week_num'] = last_sale['Week_num'].astype(np.int8)\n",
    "\n",
    "df = df.merge(last_sale, on=['Week_num','DEPARTMENT_ID'], how='left')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ed0d3bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23488211631774902"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Months since the first sale for each shop/item pair and for item only.\n",
    "ts = time.time()\n",
    "df['department_district_first_sale'] = df['Week_num'] - df.groupby(['DEPARTMENT_ID','DISTRICT'])['Week_num'].transform('min')\n",
    "df['department_first_sale'] = df['Week_num'] - df.groupby('DEPARTMENT_ID')['Week_num'].transform('min')\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c0fe5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Week_num > 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aedd0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FISCAL_WEEK_ID</th>\n",
       "      <th>DEPARTMENT_ID</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>GROSS_SALES</th>\n",
       "      <th>PROMO_DISCOUNT</th>\n",
       "      <th>CLEARANCE_DISCOUNT</th>\n",
       "      <th>COUPON_DISCOUNT</th>\n",
       "      <th>MISCELLANOUS_DISCOUNT</th>\n",
       "      <th>ACTUAL_SALES</th>\n",
       "      <th>UNITS_SOLD</th>\n",
       "      <th>...</th>\n",
       "      <th>week_market_avg_actual_sales_lag_4</th>\n",
       "      <th>week_department_market_avg_actual_sales_lag_4</th>\n",
       "      <th>delta_price_lag</th>\n",
       "      <th>delta_actual_sales_lag_4</th>\n",
       "      <th>Month_num</th>\n",
       "      <th>year</th>\n",
       "      <th>department_district_last_sale</th>\n",
       "      <th>department_last_sale</th>\n",
       "      <th>department_district_first_sale</th>\n",
       "      <th>department_first_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FISCAL_WEEK_ID, DEPARTMENT_ID, DISTRICT, GROSS_SALES, PROMO_DISCOUNT, CLEARANCE_DISCOUNT, COUPON_DISCOUNT, MISCELLANOUS_DISCOUNT, ACTUAL_SALES, UNITS_SOLD, INITIAL_MARGIN, MARKET, Week_num, DEPARTMENT, SHOP, SBU, department_code, shop_code, UNIT_PRICE, ACTUAL_SALES_lag_4, ACTUAL_SALES_lag_8, ACTUAL_SALES_lag_12, ACTUAL_SALES_lag_26, ACTUAL_SALES_lag_52, department_avg_sale_last_26, department_std_sale_last_26, department_avg_sale_last_52, department_std_sale_last_52, district_avg_sale_last_26, district_std_sale_last_26, district_avg_sale_last_52, district_std_sale_last_52, market_avg_sale_last_52, market_std_sale_last_52, dep_avg_sale_last_52, dep_std_sale_last_52, shop_avg_sale_last_52, shop_std_sale_last_52, week_avg_actual_sales_lag_4, week_dept_avg_actual_sales_lag_4, week_dept_avg_actual_sales_lag_8, week_dept_avg_actual_sales_lag_12, week_dept_avg_actual_sales_lag_26, week_dept_avg_actual_sales_lag_52, week_district_avg_actual_sales_lag_4, week_district_avg_actual_sales_lag_8, week_district_avg_actual_sales_lag_12, week_district_avg_actual_sales_lag_26, week_district_avg_actual_sales_lag_52, week_market_avg_actual_sales_lag_4, week_department_market_avg_actual_sales_lag_4, delta_price_lag, delta_actual_sales_lag_4, Month_num, year, department_district_last_sale, department_last_sale, department_district_first_sale, department_first_sale]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 59 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Month_num'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f73a1a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FISCAL_WEEK_ID                                        0\n",
       "DEPARTMENT_ID                                         0\n",
       "DISTRICT                                              0\n",
       "GROSS_SALES                                           0\n",
       "PROMO_DISCOUNT                                        0\n",
       "CLEARANCE_DISCOUNT                                    0\n",
       "COUPON_DISCOUNT                                       0\n",
       "MISCELLANOUS_DISCOUNT                                 0\n",
       "ACTUAL_SALES                                          0\n",
       "UNITS_SOLD                                            0\n",
       "INITIAL_MARGIN                                        0\n",
       "MARKET                                                0\n",
       "Week_num                                              0\n",
       "DEPARTMENT                                            0\n",
       "SHOP                                                  0\n",
       "SBU                                                   0\n",
       "department_code                                       0\n",
       "shop_code                                             0\n",
       "UNIT_PRICE                                            0\n",
       "ACTUAL_SALES_lag_4                                    0\n",
       "ACTUAL_SALES_lag_8                                    0\n",
       "ACTUAL_SALES_lag_12                                   0\n",
       "ACTUAL_SALES_lag_26                                   0\n",
       "ACTUAL_SALES_lag_52                                   0\n",
       "department_avg_sale_last_26                           0\n",
       "department_std_sale_last_26                           0\n",
       "department_avg_sale_last_52                           0\n",
       "department_std_sale_last_52                           0\n",
       "district_avg_sale_last_26                             0\n",
       "district_std_sale_last_26                             0\n",
       "district_avg_sale_last_52                             0\n",
       "district_std_sale_last_52                             0\n",
       "market_avg_sale_last_52                               0\n",
       "market_std_sale_last_52                               0\n",
       "dep_avg_sale_last_52                                  0\n",
       "dep_std_sale_last_52                                  0\n",
       "shop_avg_sale_last_52                                 0\n",
       "shop_std_sale_last_52                                 0\n",
       "week_avg_actual_sales_lag_4                           0\n",
       "week_dept_avg_actual_sales_lag_4                      0\n",
       "week_dept_avg_actual_sales_lag_8                      0\n",
       "week_dept_avg_actual_sales_lag_12                     0\n",
       "week_dept_avg_actual_sales_lag_26                     0\n",
       "week_dept_avg_actual_sales_lag_52                     0\n",
       "week_district_avg_actual_sales_lag_4                  0\n",
       "week_district_avg_actual_sales_lag_8                  0\n",
       "week_district_avg_actual_sales_lag_12                 0\n",
       "week_district_avg_actual_sales_lag_26                 0\n",
       "week_district_avg_actual_sales_lag_52                 0\n",
       "week_market_avg_actual_sales_lag_4                    0\n",
       "week_department_market_avg_actual_sales_lag_4         0\n",
       "delta_price_lag                                       0\n",
       "delta_actual_sales_lag_4                          13448\n",
       "Month_num                                             0\n",
       "year                                                  0\n",
       "department_district_last_sale                    716684\n",
       "department_last_sale                             643016\n",
       "department_district_first_sale                        0\n",
       "department_first_sale                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd62da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_data_for_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd1588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c5eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
